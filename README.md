# SpamDetection_Tests

Решение задачи бинарной классификации с помощью методов NLP -- классификация сообщений (электронных писем) на "spam" (1) и "ham" (0).

## Datasets

Для обучения были выбраны два популярных набора данных с Kaggle, соответствующих заданию: единый CSV-файл со строковыми сообщениями и бинарной переменной классификации.
- **The Enron Email Dataset** [https://www.kaggle.com/datasets/mohinurabdurahimova/maildataset]
- **Ling-Spam Dataset** [https://www.kaggle.com/datasets/mandygu/lingspam-dataset]
- **Валидационный набор писем** [https://disk.yandex.ru/d/mJ_9zG3dX3eZgg]

## Алгоритм

Для решения задачи был выбран метод Наивного Байеса с частотной векторизацией (CountVectorizer и TfidfVectorizer).  Для поиска оптимальных параметров модели использовался прямой перебор с кросс-валидацией (GridSearchCV).
В качестве целевой метрики для оптимизации был выбран F1-score, обеспечивающий взвешенную оценку качества классификации по обоим классам.

## Структура проекта

- `dataset_loader.py`: Функции для упрощения загрузки используемых данных:
    - `download_dataset(name: str, return_type: Literal["tuple", "dataframe"] = "tuple")`: Загружает датасет в виде кортежа (X, y) или pandas DataFrame.
    - `merged_dataset(ds_names: List[str], frac: float=1) -> pd.DataFrame`: Объединяет несколько датасетов в один DataFrame с возможностью выбора доли данных для каждого датасета (`frac`).
- `main.py`: Подбор, тренировка и сохранение моделей.
- `eml_loader.py`: Преобразование двух директорий .eml-файлов в pandas DataFrame (чтение файлов, сохранение в один .csv).
- `test.py`: Применение обученных функций для получения результатов на валидационном наборе данных.

## Инструкция по запуску

Рекомендуется использовать Python 3.11 или выше (версия разработки 3.13 также подойдет). В репозитории присутствует файл `requirements.txt` с необходимыми зависимостями.

1.  Установите зависимости: `pip install -r requirements.txt`
2.  Запустите `main.py` для загрузки данных и подбора лучшего пайплайна.
3.  Используйте `test.py` для получения результатов на любом наборе правильно структурированных данных.
4.  (Optional) Преобразуйте директории EML файлов в один CSV с помощью `eml_loader.py`.

## Результаты

### Enron Dataset

    best_enron_pipeline = Pipeline(
        steps=[
            ('vectorizer', CountVectorizer(stop_words='english', max_df=0.2, min_df=3, ngram_range=(1, 1)),
            ('classifier', MultinomialNB(alpha=1.0))
        ]
    )

f1_0 = 0.99  (F1-score для класса "ham")
f1_1 = 0.95  (F1-score для класса "spam")

### Ling-Spam Dataset

    best_lingspam_pipeline = Pipeline(
        steps=[
            ('vectorizer', TfidfVectorizer(stop_words='english', max_df=0.6, min_df=5, ngram_range=(1, 2))),
            ('classifier', MultinomialNB(alpha=0.1))
        ]
    )

f1_0 = 0.997  (F1-score для класса "ham")
f1_1 = 0.98   (F1-score для класса "spam")

### Объединение датасетов

Частотная векторизация и Наивный Байес демонстрируют чувствительность к входным данным (возможно, из-за недостаточного объема данных). Модель, обученная на Enron, показывает лишь (f1_0, f1_1) = (0.73, 0.76) на Lingspam.  Enron содержит в два раза больше записей, чем Ling-spam.

Для повышения стабильности решения датасеты были объединены. Лучшая модель:

    combined_pipeline = Pipeline(
        steps=[
            ('vectorizer', TfidfVectorizer(stop_words='english', max_df=0.2, min_df=3, ngram_range=(1, 1))),
            ('classifier', MultinomialNB(alpha=0.1))
        ]
    )

На всём объеме тренировочных данных результаты: (f1_0, f1_1, f1_weighted) = (0.996, 0.974, 0.992)

Решение стало стабильнее, для каждого из тренировочных наборов значение `f1_weighted` превысило 0.99.

### Валидация

Валидационный набор электронных писем снова показал недостаточную стабильность предложенного решения при классификации неизвестных писем: метрики снизились до (f1_0, f1_1, f1_weighted) = (0.78, 0.86, 0.83). В валидационном наборе спама чуть больше половины, что может объяснять смещение метрики в сторону этого класса.

## Развитие

### Мультиязычность

Существует несколько подходов к решению задачи мультиязычности:
- Использование многоязычных эмбеддингов.
- Обучение нескольких моделей для разных языков.
- Перевод писем на единый язык.

Каждый подход имеет свои преимущества и недостатки. Многоязычная векторизация может быть наиболее точной, но ресурсозатратной.  Обучение нескольких моделей добавляет сложность, а спам часто использует несколько языков или несуществующие слова для обхода фильтров, что снижает эффективность этого подхода.

### Concept Drift и дообучение

Как показано в результатах, простые методы NLP могут быть нестабильны из-за concept drift (изменения характеристик данных со временем). Решением является регулярное дообучение модели на новых, актуальных данных.
