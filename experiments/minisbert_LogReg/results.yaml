accuracy: 0.9911504424778761
auc: 0.9951887975738061
report:
  '0':
    precision: 0.9948892674616695
    recall: 0.9948892674616695
    f1-score: 0.9948892674616695
    support: 587.0
  '1':
    precision: 0.967032967032967
    recall: 0.967032967032967
    f1-score: 0.967032967032967
    support: 91.0
  accuracy: 0.9911504424778761
  macro avg:
    precision: 0.9809611172473183
    recall: 0.9809611172473183
    f1-score: 0.9809611172473183
    support: 678.0
  weighted avg:
    precision: 0.9911504424778761
    recall: 0.9911504424778761
    f1-score: 0.9911504424778761
    support: 678.0
best_arch:
  vec:
    class_name: SBERTVectorizer
    params:
      model_name: all-MiniLM-L6-v2
      batch_size: 16
  clf:
    class_name: LogisticRegression
    params:
      penalty: l2
      dual: false
      tol: 0.0001
      C: 10
      fit_intercept: true
      intercept_scaling: 1
      class_weight: null
      random_state: null
      solver: saga
      max_iter: 100
      multi_class: deprecated
      verbose: 0
      warm_start: false
      n_jobs: null
      l1_ratio: null
timing:
  train_time_sec: 620.6890617000026
  inference:
    batch_median_sec: 5.030492900012177
    per_sample_avg_sec: 0.007419606047215601
    throughput_samples_per_sec: 134.7780453081166
    per_sample_stats:
      median: 0.008476449998852331
      p95: 0.02507466500028386
      samples_measured: 100
    probability_time_sec: 5.010949000003166
model_size_bytes: 91397677
