experiment: minisbert_LogReg
timestamp: '2025-08-12T17:38:55Z'
pipeline_file: final/best_pipeline.joblib
model:
  vec:
    class_name: SBERTVectorizer
    params:
      batch_size: 16
      model_name: all-MiniLM-L6-v2
  clf:
    class_name: LogisticRegression
    params:
      C: 10
      class_weight: null
      dual: false
      fit_intercept: true
      intercept_scaling: 1
      l1_ratio: null
      max_iter: 100
      multi_class: deprecated
      n_jobs: null
      penalty: l2
      random_state: null
      solver: saga
      tol: 0.0001
      verbose: 0
      warm_start: false
data:
  n_total: 1596
  n_sample: 500
  sample_seed: 42
metrics:
  batch_predict:
    median_sec: 8.132382300000017
    repeats_sec:
    - 8.141923799999859
    - 8.132382300000017
    - 7.95803920000003
  per_sample:
    median_ms: 19.773949999944307
    p95_ms: 26.091074999942517
    samples_measured: 50
  throughput_samples_per_sec: 61.48259901652667
  predict_proba_sec: 8.069350099999838
  auc: 0.8126534369885433
  accuracy: 0.744
  classification_report:
    '0':
      precision: 0.65
      recall: 0.6914893617021277
      f1-score: 0.6701030927835051
      support: 188.0
    '1':
      precision: 0.8066666666666666
      recall: 0.7756410256410257
      f1-score: 0.7908496732026143
      support: 312.0
    accuracy: 0.744
    macro avg:
      precision: 0.7283333333333333
      recall: 0.7335651936715767
      f1-score: 0.7304763829930597
      support: 500.0
    weighted avg:
      precision: 0.74776
      recall: 0.744
      f1-score: 0.7454489589650293
      support: 500.0
model_size_bytes: 91397917
env:
  python: 3.11.3
  sklearn: 1.7.1
  platform: Windows-10-10.0.19045-SP0
